{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import facenet\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import imageio\n",
    "import os\n",
    "from tensorflow.python.platform import gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prewhiten(x):\n",
    "    mean = np.mean(x)\n",
    "    std = np.std(x)\n",
    "    std_adj = np.maximum(std, 1.0/np.sqrt(x.size))\n",
    "    y = np.multiply(np.subtract(x, mean), 1/std_adj)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, input_map=None):\n",
    "    # Check if the model is a model directory (containing a metagraph and a checkpoint file)\n",
    "    #  or if it is a protobuf file with a frozen graph\n",
    "    model_exp = os.path.expanduser(model)\n",
    "    if (os.path.isfile(model_exp)):\n",
    "        print('Model filename: %s' % model_exp)\n",
    "        with gfile.FastGFile(model_exp,'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "            tf.import_graph_def(graph_def, input_map=input_map, name='')\n",
    "    else:\n",
    "        print('Model directory: %s' % model_exp)\n",
    "        meta_file, ckpt_file = get_model_filenames(model_exp)\n",
    "        \n",
    "        print('Metagraph file: %s' % meta_file)\n",
    "        print('Checkpoint file: %s' % ckpt_file)\n",
    "      \n",
    "        saver = tf.train.import_meta_graph(os.path.join(model_exp, meta_file), input_map=input_map)\n",
    "        saver.restore(tf.get_default_session(), os.path.join(model_exp, ckpt_file))\n",
    "    \n",
    "def get_model_filenames(model_dir):\n",
    "    files = os.listdir(model_dir)\n",
    "    meta_files = [s for s in files if s.endswith('.meta')]\n",
    "    if len(meta_files)==0:\n",
    "        raise ValueError('No meta file found in the model directory (%s)' % model_dir)\n",
    "    elif len(meta_files)>1:\n",
    "        raise ValueError('There should not be more than one meta file in the model directory (%s)' % model_dir)\n",
    "    meta_file = meta_files[0]\n",
    "    ckpt = tf.train.get_checkpoint_state(model_dir)\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        ckpt_file = os.path.basename(ckpt.model_checkpoint_path)\n",
    "        return meta_file, ckpt_file\n",
    "\n",
    "    meta_files = [s for s in files if '.ckpt' in s]\n",
    "    max_step = -1\n",
    "    for f in files:\n",
    "        step_str = re.match(r'(^model-[\\w\\- ]+.ckpt-(\\d+))', f)\n",
    "        if step_str is not None and len(step_str.groups())>=2:\n",
    "            step = int(step_str.groups()[1])\n",
    "            if step > max_step:\n",
    "                max_step = step\n",
    "                ckpt_file = step_str.groups()[0]\n",
    "    return meta_file, ckpt_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(image_names, model_dir, chunk_size = 512):\n",
    "    with tf.Graph().as_default():\n",
    "        with tf.Session() as sess:\n",
    "            load_model(model_dir)\n",
    "            images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\n",
    "            embeddings_placeholder = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\n",
    "            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\n",
    "            if len(image_names)<chunk_size:\n",
    "                images = np.asarray([prewhiten(imageio.imread(image_name)) for image_name in image_names])\n",
    "                feed_dict = {images_placeholder:images, phase_train_placeholder:False}\n",
    "                embeddings = sess.run(embeddings_placeholder, feed_dict=feed_dict)\n",
    "            else:\n",
    "                embeddings = np.empty((0, 128))\n",
    "                for i in range(0, len(image_names), chunk_size):\n",
    "                    image_names_chunk = image_names[i:min(i+chunk_size, len(image_names))]\n",
    "                    images_chunk = np.asarray([prewhiten(imageio.imread(image_name)) for image_name in image_names_chunk])\n",
    "                    feed_dict = {images_placeholder:images_chunk, phase_train_placeholder:False}\n",
    "                    embedding_chunk = sess.run(embeddings_placeholder, feed_dict=feed_dict)\n",
    "                    embeddings = np.vstack((embeddings,embedding_chunk))\n",
    "            return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CCNA training data evaluation\n",
    "ccna_data = '/datadrive/images/ccna_test_data_latest_full/all_cropped_images'\n",
    "ccna_labels = os.listdir(ccna_data)\n",
    "ccna_sku_full_paths = [ccna_data+'/'+sku for sku in ccna_labels]\n",
    "ccna_embedding_dict = {}\n",
    "ccna_sku_image_names_dict = {}\n",
    "ccna_full_training_image_names_list = []\n",
    "for sku in ccna_sku_full_paths:\n",
    "    if os.path.isdir(sku):\n",
    "        sku_image_names = [sku+'/'+f for f in os.listdir(sku)]\n",
    "        ccna_sku_image_names_dict[sku.split('/')[-1]] = sku_image_names\n",
    "        ccna_full_training_image_names_list += sku_image_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model filename: /home/caffe/facenet/sku_triplet_500k.pb\n"
     ]
    }
   ],
   "source": [
    "full_training_embeddings = generate_embeddings(ccna_full_training_image_names_list, '/home/caffe/facenet/sku_triplet_500k.pb', chunk_size = 512)\n",
    "np.save('CCNA_full_testing_embeddings_facenet_model_v1.npy', full_training_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ccna_full_testing_image_names_list.npy', np.asarray(ccna_full_training_image_names_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
